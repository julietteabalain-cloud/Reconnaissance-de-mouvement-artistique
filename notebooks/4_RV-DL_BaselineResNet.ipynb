{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e4cbe4e",
   "metadata": {},
   "source": [
    "# <center> Baseline ResNet\n",
    "\n",
    "Nous allons utiliser ResNet pour nous cr√©er une baseline de comparaison, mais √©galement pour comparer les performances avec la partie vision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b520255",
   "metadata": {},
   "source": [
    "## Imports de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12644ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b9fb1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Reconnaissance-de-mouvement-artistique' already exists and is not an empty directory.\n",
      "remote: Enumerating objects: 11, done.\u001b[K\n",
      "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 6 (delta 5), reused 6 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (6/6), 800 bytes | 400.00 KiB/s, done.\n",
      "From https://github.com/julietteabalain-cloud/Reconnaissance-de-mouvement-artistique\n",
      "   1b8b998..e9decc7  main       -> origin/main\n",
      "Updating 1b8b998..e9decc7\n",
      "Fast-forward\n",
      " notebooks/4_RV-DL_BaselineResNet.ipynb | 55 \u001b[32m+++++++++++++++\u001b[m\u001b[31m-------------------\u001b[m\n",
      " src/models.py                          |  2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
      " 2 files changed, 25 insertions(+), 32 deletions(-)\n",
      "/content/Reconnaissance-de-mouvement-artistique\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Pour que notre archi fonctionne avec google colab \n",
    "    \n",
    "!git clone https://github.com/julietteabalain-cloud/Reconnaissance-de-mouvement-artistique.git\n",
    "!cd /content/Reconnaissance-de-mouvement-artistique && git pull\n",
    "%cd /content/Reconnaissance-de-mouvement-artistique \n",
    "import sys\n",
    "sys.path.append(\".\")  # pour que src/ soit importable\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7ce7073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from src.dataset_dl import ArtDataset\n",
    "from src.train import train_model, train_one_epoch, validate_one_epoch\n",
    "\n",
    "from src.dataset import load_df_train_test_val, load_df\n",
    "from src.preprocessing import clean_dataset\n",
    "\n",
    "from src.models import get_resnet18\n",
    "from src.evaluate import *\n",
    "from src.utils import set_seed\n",
    "\n",
    "#Fixer l'initialisation al√©atoire pour la reproductibilit√©\n",
    "set_seed(42)\n",
    "\n",
    "#pour avoir acces au GPU si dispo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f29bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/Reconnaissance-de-mouvement-artistique/src/preprocessing.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"style_encoded\"] = le.fit_transform(df_train[\"style\"])\n",
      "/content/Reconnaissance-de-mouvement-artistique/src/preprocessing.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[\"style_encoded\"]   = le.transform(df_val[\"style\"])\n",
      "/content/Reconnaissance-de-mouvement-artistique/src/preprocessing.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"style_encoded\"]  = le.transform(df_test[\"style\"])\n",
      "/content/Reconnaissance-de-mouvement-artistique/src/preprocessing.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"style_encoded\"]      = le.transform(df[\"style\"])\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"/content/deepl-projet\")\n",
    "DATA_ROOT = Path(\"/content/drive/MyDrive/DeepLearning/WikiArt_Subset\")\n",
    "\n",
    "\n",
    "df_test, df_train, df_val = load_df_train_test_val(DATA_ROOT)\n",
    "df = load_df(DATA_ROOT)\n",
    "\n",
    "df, df_train, df_val, df_test = clean_dataset(df, df_train, df_val, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0004a255",
   "metadata": {},
   "source": [
    "## 1. Partie Classique / Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221dea5f",
   "metadata": {},
   "source": [
    "### 1.1 Pr√©paration du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76b8b649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 - Style: Expressionism - Style number: 9- Style code: 7\n",
      "Sample 1 - Style: Fauvism - Style number: 10- Style code: 8\n",
      "Sample 2 - Style: Symbolism - Style number: 24- Style code: 21\n",
      "Sample 3 - Style: Abstract_Expressionism - Style number: 0- Style code: 0\n",
      "Sample 4 - Style: Fauvism - Style number: 10- Style code: 8\n",
      "Number of unique styles: 23\n",
      "Unique styles: [ 9 10 24  0 11  5 26  6 17 18 21 22 19  7 20 12  4 13  8 23 15  3 14]\n",
      "Unique styles names: [ 7  8 21  0  9  3 22  4 14 15 18 19 16  5 17 10  2 11  6 20 13  1 12]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Sample {i} - Style: {df_train.iloc[i]['style_name']} - Style number: {df_train.iloc[i]['style']}- Style code: {df_train.iloc[i]['style_encoded']}\")\n",
    "\n",
    "print(f\"Number of unique styles: {df_train['style_name'].nunique()}\")\n",
    "print(f\"Unique styles: {df_train['style'].unique()}\")\n",
    "print(f\"Unique styles names: {df_train['style_encoded'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352dbc30",
   "metadata": {},
   "source": [
    "On ajoute de la data augmentation pour √©viter le surapprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e88b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ), \n",
    "    # ajout de data augmentation pour le training set\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ), \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f7a1433",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_ROOT_TRAIN = DATA_ROOT / \"train\"\n",
    "IMAGE_ROOT_VAL = DATA_ROOT / \"val\"\n",
    "IMAGE_ROOT_TEST = DATA_ROOT / \"test\"\n",
    "\n",
    "train_dataset = ArtDataset(\n",
    "    df_train,\n",
    "    IMAGE_ROOT_TRAIN,\n",
    "    transform=transform_train\n",
    ")\n",
    "\n",
    "val_dataset = ArtDataset(\n",
    "    df_val,\n",
    "    IMAGE_ROOT_VAL,\n",
    "    transform=transform_val\n",
    ")\n",
    "\n",
    "test_dataset = ArtDataset(\n",
    "    df_test,\n",
    "    IMAGE_ROOT_TEST,\n",
    "    transform=transform_val\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c886e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32  \n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,     # ajuster selon ton CPU\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,     # ajuster selon ton CPU\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,     # ajuster selon ton CPU\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec7f58",
   "metadata": {},
   "source": [
    "### 1.2 Charger le mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04434f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min label: 0\n",
      "Max label: 26\n",
      "Nombre de classes uniques: 23\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "num_classes = df_train[\"style\"].nunique()\n",
    "print(\"Min label:\", df_train[\"style\"].min())\n",
    "print(\"Max label:\", df_train[\"style\"].max())\n",
    "print(\"Nombre de classes uniques:\", df_train[\"style\"].nunique())\n",
    "\n",
    "\n",
    "print(str(df_train[\"style\"].nunique()))\n",
    "model = get_resnet18(num_classes=num_classes, device=device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.fc.parameters(),\n",
    "    lr=1e-3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c481f",
   "metadata": {},
   "source": [
    "### 1.3 Entrainement du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84bf71",
   "metadata": {},
   "source": [
    "On commence avec 3 epoch et on freeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00bd260e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2289.jpg\n",
      "9\n",
      "7\n",
      "Expressionism\n",
      "    style              style_name\n",
      "1       9           Expressionism\n",
      "2      10                 Fauvism\n",
      "4      24               Symbolism\n",
      "5       0  Abstract_Expressionism\n",
      "6      10                 Fauvism\n",
      "7      11        High_Renaissance\n",
      "8       5    Color_Field_Painting\n",
      "9      26                 Ukiyo_e\n",
      "10      6    Contemporary_Realism\n",
      "11      9           Expressionism\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "row = df_train.iloc[0]\n",
    "\n",
    "print(row[\"filename\"])\n",
    "print(row[\"style\"])\n",
    "print(row[\"style_encoded\"])\n",
    "\n",
    "print(row[\"style_name\"])\n",
    "print(df_train[[\"style\",\"style_name\"]].head(10))\n",
    "\n",
    "print((IMAGE_ROOT_TRAIN / str(row[\"style\"]) / row[\"filename\"]).exists())\n",
    "print((IMAGE_ROOT_TRAIN / str(row[\"style_encoded\"]) / row[\"filename\"]).exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79e2b5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.7950 | Train Acc: 0.1886 | Val Loss: 6.2496 | Val Acc: 0.0612\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.2946 | Train Acc: 0.3089 | Val Loss: 8.3454 | Val Acc: 0.0568\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.1687 | Train Acc: 0.3405 | Val Loss: 7.9941 | Val Acc: 0.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "history_freeze = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398941b0",
   "metadata": {},
   "source": [
    "unfreeze complet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "711fd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae70ca4",
   "metadata": {},
   "source": [
    "On continue avec cette fois 10 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca09f34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9785 | Train Acc: 0.3771 | Val Loss: 8.0839 | Val Acc: 0.0743\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5605 | Train Acc: 0.5032 | Val Loss: 6.7130 | Val Acc: 0.0940\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2759 | Train Acc: 0.6049 | Val Loss: 7.8314 | Val Acc: 0.0925\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0399 | Train Acc: 0.6751 | Val Loss: 6.5696 | Val Acc: 0.1275\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8368 | Train Acc: 0.7494 | Val Loss: 6.1008 | Val Acc: 0.1275\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6665 | Train Acc: 0.8080 | Val Loss: 5.0217 | Val Acc: 0.1639\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5360 | Train Acc: 0.8510 | Val Loss: 7.8344 | Val Acc: 0.1180\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|‚ñà‚ñà‚ñé       | 46/202 [00:57<02:35,  1.00it/s]"
     ]
    }
   ],
   "source": [
    "history_unfreeze = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=10,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e298c",
   "metadata": {},
   "source": [
    "### 1.4 Evaluation du mod√®le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd628572",
   "metadata": {},
   "source": [
    "#### 1.4.1 Evaluation train val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2a1378",
   "metadata": {},
   "source": [
    "Accuracy (pr√©cision)  globale :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bdb726",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history_freeze[\"train_acc\"] + history_unfreeze[\"train_acc\"]\n",
    "val_acc   = history_freeze[\"val_acc\"]   + history_unfreeze[\"val_acc\"]\n",
    "\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "plt.title(\"ResNet18 Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103c186",
   "metadata": {},
   "source": [
    "Matrice de confusion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7763cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix :\n",
    "\n",
    "class_names = sorted(df_train[\"style_name\"].unique())\n",
    "\n",
    "cm = compute_confusion_matrix(\n",
    "    model,\n",
    "    val_loader,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(cm, class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d4f051",
   "metadata": {},
   "source": [
    "Accuracy par style :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b9996",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(df_train[\"style\"].unique())\n",
    "\n",
    "acc_per_style = accuracy_per_class(\n",
    "    model,\n",
    "    val_loader,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "results = list(zip(class_names, acc_per_style))\n",
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for style, acc in results:\n",
    "    print(f\"{style}: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2baa1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_accuracy_per_style(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2c487",
   "metadata": {},
   "source": [
    "#### 1.4.2 Evaluation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ecbed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_weights = model.state_dict()\n",
    "\n",
    "test_acc, test_cm, report = evaluate_model(model, test_loader, device)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532f8a5",
   "metadata": {},
   "source": [
    "### 1.5 Second mod√®le ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a30523",
   "metadata": {},
   "source": [
    "Surapprentissage tr√®s fort; mod√®le utilis√© : Freeze 3 epochs, Unfreeze tout 10 epochs √† 1e-4\n",
    "On change de strat√©gie : \n",
    "Early stopping, dropout, unfreeze unqiuement layer 4, label smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f1811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_02 = get_resnet18(num_classes=num_classes, device=device, drop=True)\n",
    "\n",
    "# ajout de label smoothing pour la cross entropy loss\n",
    "# label smoothing permet de rendre le mod√®le moins confiant dans ses pr√©dictions, \n",
    "# ce qui peut aider √† am√©liorer la g√©n√©ralisation et r√©duire le surapprentissage\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model_02.fc.parameters(),  \n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13846e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3):\n",
    "        self.patience = patience\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.counter = 0\n",
    "        self.stop = False\n",
    "\n",
    "    def step(self, val_loss):\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "\n",
    "NUM_EPOCHS_FREEZE = 3\n",
    "history_freeze_02 = train_model(\n",
    "    model_02,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=NUM_EPOCHS_FREEZE,\n",
    "    early_stopping=early_stopping  \n",
    ")\n",
    "\n",
    "# D√©bloquer layer4 et fc pour le fine-tuning\n",
    "for param in model_02.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_02.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model_02.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model_02.parameters(),\n",
    "    lr=1e-4, \n",
    "    weight_decay=1e-4)\n",
    "\n",
    "NUM_EPOCHS_UNFREEZE = 7\n",
    "\n",
    "history_unfreeze_02 = train_model(\n",
    "    model_02,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=NUM_EPOCHS_UNFREEZE,\n",
    "    early_stopping=early_stopping\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a99955",
   "metadata": {},
   "source": [
    "### 1.6 Evaluation du nouveau mod√®le "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d0499",
   "metadata": {},
   "source": [
    "#### 1.6.1 Evaluation avec train + val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfddee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history_unfreeze_02[\"train_acc\"] + history_freeze_02[\"train_acc\"]\n",
    "val_acc   = history_unfreeze_02[\"val_acc\"] + history_freeze_02[\"val_acc\"]\n",
    "\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "plt.title(\"ResNet18 Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af06c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix :\n",
    "\n",
    "class_names = sorted(df_train[\"style\"].unique())\n",
    "\n",
    "cm = compute_confusion_matrix(\n",
    "    model_02,\n",
    "    val_loader,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(cm, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ec895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(df_train[\"style\"].unique())\n",
    "\n",
    "acc_per_style = accuracy_per_class(\n",
    "    model_02,\n",
    "    val_loader,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "results = list(zip(class_names, acc_per_style))\n",
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for style, acc in results:\n",
    "    print(f\"{style}: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ad9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_accuracy_per_style(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d4e067",
   "metadata": {},
   "source": [
    "#### 1.6.2 Evaluation sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f97dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_weights = model_02.state_dict()\n",
    "\n",
    "test_acc, test_cm, report = evaluate_model(model_02, test_loader, device)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc9537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Confusion Matrix:\")\n",
    "plot_confusion_matrix(test_cm, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e40e36",
   "metadata": {},
   "source": [
    "### 1.5 Sauvegarde du mod√®le entrain√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52447d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SAVE_DIR = \"/content/drive/MyDrive/models\"\n",
    "model_name_02 = \"resnet18_baseline_02.pt\"\n",
    "os.makedirs(\"/content/drive/MyDrive/models\", exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(SAVE_DIR, model_name_02)\n",
    "\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    \"num_classes\": num_classes,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"batch_size\": train_loader.batch_size,\n",
    "    \"num_epochs\": len(history_02[\"train_loss\"]),\n",
    "    \"history\": history_02,\n",
    "    \"architecture\": \"resnet18_baseline_frozen_dropout\",\n",
    "}, save_path)\n",
    "\n",
    "# Pour charger le mod√®le plus tard :\n",
    "# checkpoint = torch.load(save_path, map_location=device)\n",
    "\n",
    "# model = get_resnet18(\n",
    "#     num_classes=checkpoint[\"num_classes\"],\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fedb8a5",
   "metadata": {},
   "source": [
    "\n",
    "üîπ Phase B ‚Äì Pr√©parer l‚Äôinfrastructure pour ablation\n",
    "\n",
    " Cr√©er fonction apply_low_pass(image)\n",
    "\n",
    " Cr√©er fonction apply_high_pass(image)\n",
    "\n",
    " Version dataset avec filtrage optionnel\n",
    "\n",
    " R√©entra√Æner ResNet sur chaque version\n",
    "\n",
    " Comparer accuracy globale\n",
    "\n",
    " Comparer accuracy par style\n",
    "\n",
    " Graphique comparatif final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
