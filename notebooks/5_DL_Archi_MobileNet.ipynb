{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e193b172",
   "metadata": {},
   "source": [
    "# <center> Tests de différentes architectures MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58be3a6",
   "metadata": {},
   "source": [
    "On compare ici différentes architectures avec exactement les mêmes hyperparamètres que pour ResNet18 c'est à dire : \n",
    "- Même split train / val / test\n",
    "- Même preprocessing\n",
    "- Même nombre d’epochs\n",
    "- Même optimizer (Adam)\n",
    "- Même early stopping\n",
    "\n",
    "Stratégie en 2 phases :\n",
    "\n",
    "Phase 1 — Head-only training (comme ResNet18, on freeze tous les paramètres du modèle et on entraine uniquement la couche finale)\n",
    "→ Permet comparaison équitable\n",
    "\n",
    "Phase 2 — Fine-tuning partiel (optionnel mais intéressant, on débloque les 1-2 dernières couches mais risque de surapprentissage)\n",
    "→ Permet voir si les performances stagnent à cause du gel\n",
    "\n",
    "Pour chaque modèle : \n",
    "| Modèle | Accuracy | F1 weighted | Params | Temps d’entraînement |\n",
    "| ------ | -------- | ----------- | ------ | -------------------- |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4619673",
   "metadata": {},
   "source": [
    "Nous nous consacrons dans ce notebook à tester différents arcitecture MobileNet :  \n",
    "- MobileNet  \n",
    "- EfficientNet-B1   \n",
    "\n",
    "Normalement EfficientNet équilibre parfaitement la profondeur, la largeur et la résolution de l'image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0608f23f",
   "metadata": {},
   "source": [
    "### 0. Préparation des hyper-paramètres et du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de9004c",
   "metadata": {},
   "source": [
    "#### Imports de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad3c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa0fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Pour que notre archi fonctionne avec google colab\n",
    "\n",
    "!git clone https://github.com/julietteabalain-cloud/Reconnaissance-de-mouvement-artistique.git\n",
    "!cd /content/Reconnaissance-de-mouvement-artistique && git pull\n",
    "%cd /content/Reconnaissance-de-mouvement-artistique\n",
    "import sys\n",
    "sys.path.append(\".\")  # pour que src/ soit importable\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset_dl import ArtDataset\n",
    "from src.train import train_model, train_one_epoch, validate_one_epoch\n",
    "\n",
    "from src.dataset import load_df_train_test_val, load_df\n",
    "from src.preprocessing import clean_dataset\n",
    "\n",
    "from src.models import get_model\n",
    "from src.evaluate import *\n",
    "from src.utils import set_seed\n",
    "\n",
    "#Fixer l'initialisation aléatoire pour la reproductibilité\n",
    "set_seed(42)\n",
    "\n",
    "#pour avoir acces au GPU si dispo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"/content/deepl-projet\")\n",
    "DATA_ROOT = Path(\"/content/drive/MyDrive/DeepLearning/WikiArt_Subset\")\n",
    "\n",
    "\n",
    "df_test, df_train, df_val = load_df_train_test_val(DATA_ROOT)\n",
    "df = load_df(DATA_ROOT)\n",
    "\n",
    "df, df_train, df_val, df_test = clean_dataset(df, df_train, df_val, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8a360",
   "metadata": {},
   "source": [
    "#### Dataset de deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af715e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    # ajout de data augmentation pour le training set\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_ROOT_TRAIN = DATA_ROOT / \"train\"\n",
    "IMAGE_ROOT_VAL = DATA_ROOT / \"val\"\n",
    "IMAGE_ROOT_TEST = DATA_ROOT / \"test\"\n",
    "\n",
    "train_dataset = ArtDataset(\n",
    "    df_train,\n",
    "    IMAGE_ROOT_TRAIN,\n",
    "    transform=transform_train\n",
    ")\n",
    "\n",
    "val_dataset = ArtDataset(\n",
    "    df_val,\n",
    "    IMAGE_ROOT_VAL,\n",
    "    transform=transform_val\n",
    ")\n",
    "\n",
    "test_dataset = ArtDataset(\n",
    "    df_test,\n",
    "    IMAGE_ROOT_TEST,\n",
    "    transform=transform_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,     # ajuster selon ton CPU\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,     # ajuster selon ton CPU\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,     # ajuster selon ton CPU\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a05c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3):\n",
    "        self.patience = patience\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.counter = 0\n",
    "        self.stop = False\n",
    "\n",
    "    def step(self, val_loss):\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294aee45",
   "metadata": {},
   "source": [
    "### 1. MobileNet v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f9605",
   "metadata": {},
   "source": [
    "→ Architecture légère\n",
    "→ Depthwise separable convolutions\n",
    "→ Très peu de paramètres\n",
    "\n",
    "Le problème nécessite-t-il une grande capacité ou un modèle léger suffit-il ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd2ccd3",
   "metadata": {},
   "source": [
    "#### 2.1 Charger le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47545cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mn = get_model(\"mobilenet_v2\", num_classes=23)\n",
    "model_mn = model_mn.to(device)\n",
    "\n",
    "num_classes = df_train[\"style_encoded\"].nunique()\n",
    "\n",
    "# ajout de label smoothing pour la cross entropy loss\n",
    "# label smoothing permet de rendre le modèle moins confiant dans ses prédictions,\n",
    "# ce qui peut aider à améliorer la généralisation et réduire le surapprentissage\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model_mn.fc.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47ef938",
   "metadata": {},
   "source": [
    "#### 2.2 Entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ac32dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "\n",
    "NUM_EPOCHS_FREEZE = 10\n",
    "history_freeze_02 = train_model(\n",
    "    model_mn,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=NUM_EPOCHS_FREEZE,\n",
    "    early_stopping=early_stopping\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81987d5",
   "metadata": {},
   "source": [
    "#### 2.3 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history_freeze_mn[\"train_acc\"]\n",
    "val_acc   = history_freeze_mn[\"val_acc\"]\n",
    "\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "plt.title(\"MobileNetv2 Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e29637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix :\n",
    "\n",
    "class_names = sorted(df_train[\"style\"].unique())\n",
    "\n",
    "cm = compute_confusion_matrix(\n",
    "    model_mn,\n",
    "    val_loader,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(cm, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(df_train[\"style\"].unique())\n",
    "\n",
    "acc_per_style = accuracy_per_class(\n",
    "    model_mn,\n",
    "    val_loader,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "results = list(zip(class_names, acc_per_style))\n",
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for style, acc in results:\n",
    "    print(f\"{style}: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_accuracy_per_style(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8bf68",
   "metadata": {},
   "source": [
    "#### 1.6.2 Evaluation sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2313034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_weights = model_mn.state_dict()\n",
    "\n",
    "test_acc, test_cm, report = evaluate_model(model_mn, test_loader, device)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Confusion Matrix:\")\n",
    "plot_confusion_matrix(test_cm, class_names)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
