{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91740acb",
   "metadata": {},
   "source": [
    "# <center> Reconnaissance visuelle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38303b58",
   "metadata": {},
   "source": [
    "# TODO – Reconnaissance visuelle (Visual Recognition)\n",
    "\n",
    "## 1. Préparation du dataset pour vision\n",
    "- [ ] Vérifier que le sous-dataset WikiArt est chargé avec 400 images par style.\n",
    "- [ ] Assurer la structure des dossiers : `train/val/test` avec sous-dossiers par `style`.\n",
    "- [ ] Vérifier que les fonctions `load_image()` et `DATA_ROOT` fonctionnent correctement.\n",
    "- [ ] Optionnel : filtrer images non “peinture” (statues, architecture…) pour observation qualitative.\n",
    "\n",
    "## 2. Extraction de features\n",
    "### 2.1. Contours et gradients\n",
    "- [ ] Appliquer **détecteur de Sobel** sur chaque image.\n",
    "- [ ] Calculer histogrammes pour chaque image :\n",
    "  - Magnitude des gradients\n",
    "  - Orientation des gradients\n",
    "- [ ] Vérifier que les histogrammes différencient bien styles nets vs flous.\n",
    "\n",
    "### 2.2. Descripteurs globaux\n",
    "- [ ] Extraire **HOG** (Histogram of Oriented Gradients) pour chaque image.\n",
    "- [ ] Extraire descripteurs de couleur dans les espaces **Lab** et **HSV**.\n",
    "- [ ] Normaliser et combiner toutes les features en un seul vecteur par image.\n",
    "- [ ] Créer une fonction `extract_features(image)` réutilisable.\n",
    "\n",
    "## 3. Classification SVM\n",
    "- [ ] Séparer features en train / val / test.\n",
    "- [ ] Normaliser / standardiser les features.\n",
    "- [ ] Entraîner un **SVM avec noyau RBF** sur le train.\n",
    "- [ ] Évaluer le modèle sur val et test :\n",
    "  - Précision globale\n",
    "  - F1-score par style\n",
    "  - Matrices de confusion détaillées\n",
    "- [ ] Identifier les confusions fréquentes et vérifier si elles correspondent à des confusions humaines.\n",
    "- [ ] Identifier les features les plus discriminantes pour chaque style.\n",
    "\n",
    "## 4. Analyse et visualisation\n",
    "- [ ] Visualiser quelques images par style pour valider les features.\n",
    "- [ ] Histogrammes :\n",
    "  - Nombre d’images par style\n",
    "  - Distribution des artistes par style (exclure “unknown”)\n",
    "  - Distribution des genres par style (exclure “unknown”)\n",
    "- [ ] Analyse qualitative des styles avec images non “peinture” (statues, architecture…).\n",
    "- [ ] Étudier la proportion d’artistes communs entre splits et risques de fuite.\n",
    "- [ ] Visualiser relations artistes ↔ styles et genres ↔ styles.\n",
    "- [ ] Préparer graphiques clairs pour le rapport (histogrammes, exemples d’images).\n",
    "\n",
    "## 5. Validation causale par ablation (facultatif / si FFT fait par l’autre personne)\n",
    "- [ ] Créer versions du dataset :\n",
    "  - Original\n",
    "  - Passe-haut\n",
    "  - Passe-bas\n",
    "- [ ] Entraîner un ResNet18 pour chaque version.\n",
    "- [ ] Comparer performances pour confirmer l’importance des signatures fréquentielles.\n",
    "\n",
    "## Notes\n",
    "- Toutes les fonctions d’extraction doivent être centralisées dans `src/dataset.py`.\n",
    "- Préparer les notebooks pour visualisation et tests rapides sans écraser les fichiers originaux.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
