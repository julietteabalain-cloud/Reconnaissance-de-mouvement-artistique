{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91740acb",
   "metadata": {},
   "source": [
    "# <center> Reconnaissance visuelle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7987475b",
   "metadata": {},
   "source": [
    "### 1. Préparation du dataset pour vision\n",
    "\n",
    "On choisit d'utiliser le dataset avec les transformations pertinentes appliquées après exploration des données. Notamment 4 styles avec un nombre insuffisant d'image ont été supprimés pour avoir des classes équilibrées lors de l'apprentissage dans la partie Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f966e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Reconnaissance-de-mouvement-artistique'...\n",
      "remote: Enumerating objects: 196, done.\u001b[K\n",
      "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
      "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
      "remote: Total 196 (delta 122), reused 136 (delta 62), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (196/196), 16.56 MiB | 29.70 MiB/s, done.\n",
      "Resolving deltas: 100% (122/122), done.\n",
      "Already up to date.\n",
      "/content/Reconnaissance-de-mouvement-artistique\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Pour que notre archi fonctionne avec google colab \n",
    "    \n",
    "!git clone https://github.com/julietteabalain-cloud/Reconnaissance-de-mouvement-artistique.git\n",
    "!cd /content/Reconnaissance-de-mouvement-artistique && git pull\n",
    "%cd /content/Reconnaissance-de-mouvement-artistique \n",
    "import sys\n",
    "sys.path.append(\".\")  # pour que src/ soit importable\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1453ad67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.dataset import load_df_train_test_val, load_df, load_image\n",
    "from src.preprocessing import clean_dataset\n",
    "\n",
    "#pour avoir acces au GPU si dispo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e25c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Vérification des splits :\n",
      "- Train: ['train'] (6449 images)\n",
      "- Val  : ['val'] (1373 images)\n",
      "- Test : ['test'] (1378 images)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/Reconnaissance-de-mouvement-artistique/src/preprocessing.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"style_encoded\"] = le.fit_transform(df_train[\"style\"])\n",
      "/content/Reconnaissance-de-mouvement-artistique/src/preprocessing.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[\"style_encoded\"]   = le.transform(df_val[\"style\"])\n",
      "/content/Reconnaissance-de-mouvement-artistique/src/preprocessing.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"style_encoded\"]  = le.transform(df_test[\"style\"])\n",
      "/content/Reconnaissance-de-mouvement-artistique/src/preprocessing.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"style_encoded\"]      = le.transform(df[\"style\"])\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"/content/deepl-projet\")\n",
    "DATA_ROOT = Path(\"/content/drive/MyDrive/DeepLearning/WikiArt_Subset\")\n",
    "\n",
    "\n",
    "df_test, df_train, df_val = load_df_train_test_val(DATA_ROOT)\n",
    "df_full = load_df(DATA_ROOT)\n",
    "\n",
    "df, df_train, df_val, df_test = clean_dataset(df_full, df_train, df_val, df_test)\n",
    "\n",
    "print(f\"Vérification des splits :\")\n",
    "print(f\"- Train: {df_train['split'].unique()} ({len(df_train)} images)\")\n",
    "print(f\"- Val  : {df_val['split'].unique()} ({len(df_val)} images)\")\n",
    "print(f\"- Test : {df_test['split'].unique()} ({len(df_test)} images)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46a87184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.preprocessing as preprocessing_module\n",
    "import src.vision_features_extract as vision_features_extract_module\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "vision_features_extract_module = reload(vision_features_extract_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49cd06a",
   "metadata": {},
   "source": [
    "### 2. Extraction des features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fd42cf",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.1 Contour et gradients \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f5a699",
   "metadata": {},
   "source": [
    "\n",
    "Dans cette section, nous étudions les contours présents dans les œuvres du dataset WikiArt.\n",
    "L’objectif est de déterminer si certains styles artistiques se distinguent par des contours\n",
    "plus nets ou plus flous, à l’aide d’un détecteur de Sobel et d’analyses statistiques des gradients.\n",
    "\n",
    "L'intuition serait que les styles nets (Cubisme, Pop Art, Precisionism) auraient des gradients forts, orientations bien définies, forte magnitude tandis que les styles flous (Impressionism, Romanticism, Baroque) auraient des gradients plus faibles, orientations dispersées, faible magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ef8ad",
   "metadata": {},
   "source": [
    "##### 2.1.1 Sous Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceca04a",
   "metadata": {},
   "source": [
    "Nous sélectionnons quelques styles contrastés afin de faciliter l’analyse qualitative\n",
    "et quantitative des contours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab920e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "style_name\n",
      "Pop_Art          400\n",
      "Cubism           400\n",
      "Impressionism    400\n",
      "Baroque          400\n",
      "Romanticism      400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "selected_styles = [\"Impressionism\", \"Cubism\", \"Baroque\", \"Romanticism\", \"Pop_Art\"]\n",
    "\n",
    "df_subset = df[df[\"style_name\"].isin(selected_styles)]\n",
    "print(df_subset[\"style_name\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768a906c",
   "metadata": {},
   "source": [
    "##### 2.1.2 Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aa10a69",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_sobel_examples() got multiple values for argument 'styles'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3981265849.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m vision_features_extract_module.plot_sobel_examples(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdf_subset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mload_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mDATA_ROOT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstyles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselected_styles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: plot_sobel_examples() got multiple values for argument 'styles'"
     ]
    }
   ],
   "source": [
    "vision_features_extract_module.plot_sobel_examples(\n",
    "    df_subset,\n",
    "    load_image,\n",
    "    DATA_ROOT,\n",
    "    styles=selected_styles,\n",
    "    n_images_per_style=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c73706",
   "metadata": {},
   "source": [
    "On observe que certains styles présentent des contours plus nets et structurés\n",
    "(PopArt, Cubism), tandis que d’autres styles comme l’Impressionnisme montrent\n",
    "des transitions plus douces et moins de contours marqués.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7651a5db",
   "metadata": {},
   "source": [
    "##### 2.1.3 Extraction des histogrammes de gradient\n",
    "\n",
    "Nous calculons maintenant, pour chaque image, des histogrammes de magnitude\n",
    "et d’orientation des gradients afin de quantifier la structure des contours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_gradients = vision_features_extract_module.aggregate_histograms_by_style(\n",
    "    df,\n",
    "    load_image,\n",
    "    DATA_ROOT,\n",
    "    max_images_per_style=150\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff11a18",
   "metadata": {},
   "source": [
    "##### 2.1.4 Histogrammes moyens par styles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889938c0",
   "metadata": {},
   "source": [
    "On affiche les histogrammes moyens par style de magnitude puis d'orientation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5268ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_features_extract_module.plot_mean_gradient_histograms(\n",
    "    style_gradients,\n",
    "    selected_styles,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e0a33",
   "metadata": {},
   "source": [
    "On observe seulement pour Pop Art une démarcation dans l'histogramme des orientations du gradient. Le reste des styles ne sont pas particulièrement reconnaissables via cette information. Ce n'est pas suffisant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f68a43",
   "metadata": {},
   "source": [
    "On va essayer de claculer un score par style pour determiner si c'est uns tyle aux contour fort ou fiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceee4123",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_features_extract_module.compute_scores(selected_styles, style_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35e79f0",
   "metadata": {},
   "source": [
    "Impressionnisme = score élevé : beaucoup de coups de pinceau, gradients forts, mais diffus spatialement\n",
    "\n",
    "Pop Art = score faible : aplats de couleur, grandes zones uniformes, peu de gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27bce8",
   "metadata": {},
   "source": [
    "L’analyse des gradients de Sobel montre que les styles artistiques se\n",
    "distinguent nettement par l’intensité moyenne de leurs transitions\n",
    "locales.\n",
    "Certains styles, comme l’impressionnisme ou l’expressionnisme,\n",
    "présentent une forte proportion de gradients élevés, traduisant une\n",
    "richesse de variations locales et de coups de pinceau visibles.\n",
    "À l’inverse, des styles comme le Pop Art ou le Minimalisme reposent\n",
    "davantage sur de larges aplats de couleur, générant moins de gradients\n",
    "de forte amplitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faefc9f",
   "metadata": {},
   "source": [
    "#### 2.2 Descripteurs globaux\n",
    "\n",
    "Nous utiliserons des descripteurs globaux pour\n",
    "compl´eter nos features. Nous utiliserons le descripteur\n",
    "HOG qui capturera la structure directionnelle locale (tech-\n",
    "nique picturale) ainsi qu’un descripteur couleur dans les\n",
    "espaces.\n",
    "\n",
    "\n",
    "Pour chaque image on extrait HOG : Histogram of Oriented Gradient.\n",
    "Puis on extrait des descripteurs de couleur dans les espaces Lab et HSV. \n",
    "Enfin on normalise et combine toutes ses features en un vecteur par image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = vision_features_extract_module.extract_features_dataset(df, load_image, DATA_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3d697d",
   "metadata": {},
   "source": [
    "On observe les résultats : \n",
    "D'abord en observant quels styles sont visuellement proches avec HOG + couleurs, et ensuite en observant le rendu PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284de093",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df = vision_features_extract_module.visualize_style_distances(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44beb314",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_features_extract_module.heatmap_style_distances(dist_df)\n",
    "# intéressant de comparer cette matrice a celle des distances avec les genres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf2d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_features_extract_module.pca_style_features(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef954fb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "084243dc",
   "metadata": {},
   "source": [
    "### 3. Extraction des features en CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e67d938",
   "metadata": {},
   "source": [
    "#### 3.1 StandardScaler + PCA\n",
    "\n",
    "Etant donné la grande taille des vecteurs features pour chaque image (+14000), on décide d'utiliser standardscaler puis d'appliquer PCA pour réduire la dimension du vecteur feature tout en conservant les informations pertinentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b78ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vision_features_extract_module.apply_pca_for_model(df_train, df_val, df_test, n_components=300)\n",
    "\n",
    "X_train_pca = result[\"X_train\"]\n",
    "X_val_pca   = result[\"X_val\"]\n",
    "X_test_pca  = result[\"X_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_train_pca = vision_features_extract_module.build_pca_dataframe(X_train_pca, df_train, \"train\")\n",
    "df_val_pca   = vision_features_extract_module.build_pca_dataframe(X_val_pca, df_val, \"val\")\n",
    "df_test_pca  = vision_features_extract_module.build_pca_dataframe(X_test_pca, df_test, \"test\")\n",
    "\n",
    "df_all_pca = pd.concat([df_train_pca, df_val_pca, df_test_pca])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805959b1",
   "metadata": {},
   "source": [
    "#### 3.2 Extraction en CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed27809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_pca.to_csv(\"/content/drive/MyDrive/dataset_vision_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d396241",
   "metadata": {},
   "source": [
    "# todolist\n",
    "\n",
    "## 2. Extraction de features\n",
    "### 2.1. Contours et gradients\n",
    "- [ ] Appliquer **détecteur de Sobel** sur chaque image DONE \n",
    "- [ ] Calculer histogrammes pour chaque image :DONE\n",
    "  - Magnitude des gradients\n",
    "  - Orientation des gradients\n",
    "- [ ] Vérifier que les histogrammes différencient bien styles nets vs flous. BOF\n",
    "\n",
    "### 2.2. Descripteurs globaux\n",
    "- [ ] Extraire **HOG** (Histogram of Oriented Gradients) pour chaque image. DONE\n",
    "- [ ] Extraire descripteurs de couleur dans les espaces **Lab** et **HSV**. DONE\n",
    "- [ ] Normaliser et combiner toutes les features en un seul vecteur par image. DONE\n",
    "- [ ] Créer une fonction `extract_features(image)` réutilisable.  DONE\n",
    "- Avoir un bilan \"palette de couleur\" par styles  #TODO\n",
    " \n",
    "## 3. Classification SVM\n",
    "- [ ] Séparer features en train / val / test. DONE\n",
    "- [ ] Normaliser / standardiser les features. + combiner tout les descripteurs precedents\n",
    "- [ ] Entraîner un **SVM avec noyau RBF** sur le train.\n",
    "- [ ] Évaluer le modèle sur val et test :\n",
    "  - Précision globale\n",
    "  - F1-score par style\n",
    "  - Matrices de confusion détaillées\n",
    "- [ ] Identifier les confusions fréquentes et vérifier si elles correspondent à des confusions humaines.\n",
    "- [ ] Identifier les features les plus discriminantes pour chaque style.\n",
    "\n",
    "## 4. Analyse et visualisation\n",
    "- [ ] Visualiser quelques images par style pour valider les features.\n",
    "- [ ] Histogrammes :\n",
    "  - Nombre d’images par style\n",
    "  - Distribution des artistes par style (exclure “unknown”)\n",
    "  - Distribution des genres par style (exclure “unknown”)\n",
    "- [ ] Analyse qualitative des styles avec images non “peinture” (statues, architecture…).\n",
    "- [ ] Étudier la proportion d’artistes communs entre splits et risques de fuite.\n",
    "- [ ] Visualiser relations artistes ↔ styles et genres ↔ styles.\n",
    "- [ ] Préparer graphiques clairs pour le rapport (histogrammes, exemples d’images).\n",
    "\n",
    "## 5. Validation causale par ablation (facultatif / si FFT fait par l’autre personne)\n",
    "- [ ] Créer versions du dataset :\n",
    "  - Original\n",
    "  - Passe-haut\n",
    "  - Passe-bas\n",
    "- [ ] Entraîner un ResNet18 pour chaque version.\n",
    "- [ ] Comparer performances pour confirmer l’importance des signatures fréquentielles.\n",
    "\n",
    "## Notes\n",
    "- Toutes les fonctions d’extraction doivent être centralisées dans `src/dataset.py`.\n",
    "- Préparer les notebooks pour visualisation et tests rapides sans écraser les fichiers originaux.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
