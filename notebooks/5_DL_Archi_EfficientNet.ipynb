{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29ad3ca",
   "metadata": {},
   "source": [
    "# <center> Tests de différentes architectures EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89fad28",
   "metadata": {},
   "source": [
    "On compare ici différentes architectures avec exactement les mêmes hyperparamètres que pour ResNet18 c'est à dire : \n",
    "- Même split train / val / test\n",
    "- Même preprocessing\n",
    "- Même nombre d’epochs\n",
    "- Même optimizer (Adam)\n",
    "- Même early stopping\n",
    "\n",
    "Stratégie en 2 phases :\n",
    "\n",
    "Phase 1 — Head-only training (comme ResNet18, on freeze tous les paramètres du modèle et on entraine uniquement la couche finale)\n",
    "→ Permet comparaison équitable\n",
    "\n",
    "Phase 2 — Fine-tuning partiel (optionnel mais intéressant, on débloque les 1-2 dernières couches mais risque de surapprentissage)\n",
    "→ Permet voir si les performances stagnent à cause du gel\n",
    "\n",
    "Pour chaque modèle : \n",
    "| Modèle | Accuracy | F1 weighted | Params | Temps d’entraînement |\n",
    "| ------ | -------- | ----------- | ------ | -------------------- |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab60206e",
   "metadata": {},
   "source": [
    "Nous nous consacrons dans ce notebook à tester différents arcitecture EfficientNet :  \n",
    "- EfficientNet-B0  \n",
    "- EfficientNet-B1   \n",
    "\n",
    "Normalement EfficientNet équilibre parfaitement la profondeur, la largeur et la résolution de l'image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cf2dfc",
   "metadata": {},
   "source": [
    "### 0. Préparation des hyper-paramètres et du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6bd8e4",
   "metadata": {},
   "source": [
    "#### Imports de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ac594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Pour que notre archi fonctionne avec google colab\n",
    "\n",
    "!git clone https://github.com/julietteabalain-cloud/Reconnaissance-de-mouvement-artistique.git\n",
    "!cd /content/Reconnaissance-de-mouvement-artistique && git pull\n",
    "%cd /content/Reconnaissance-de-mouvement-artistique\n",
    "import sys\n",
    "sys.path.append(\".\")  # pour que src/ soit importable\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869cafb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset_dl import ArtDataset\n",
    "from src.train import train_model, train_one_epoch, validate_one_epoch\n",
    "\n",
    "from src.dataset import load_df_train_test_val, load_df\n",
    "from src.preprocessing import clean_dataset\n",
    "\n",
    "from src.models import get_model\n",
    "from src.evaluate import *\n",
    "from src.utils import set_seed\n",
    "\n",
    "#Fixer l'initialisation aléatoire pour la reproductibilité\n",
    "set_seed(42)\n",
    "\n",
    "#pour avoir acces au GPU si dispo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"/content/deepl-projet\")\n",
    "DATA_ROOT = Path(\"/content/drive/MyDrive/DeepLearning/WikiArt_Subset\")\n",
    "\n",
    "\n",
    "df_test, df_train, df_val = load_df_train_test_val(DATA_ROOT)\n",
    "df = load_df(DATA_ROOT)\n",
    "\n",
    "df, df_train, df_val, df_test = clean_dataset(df, df_train, df_val, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd94faf",
   "metadata": {},
   "source": [
    "#### Dataset de deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    # ajout de data augmentation pour le training set\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e7bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_ROOT_TRAIN = DATA_ROOT / \"train\"\n",
    "IMAGE_ROOT_VAL = DATA_ROOT / \"val\"\n",
    "IMAGE_ROOT_TEST = DATA_ROOT / \"test\"\n",
    "\n",
    "train_dataset = ArtDataset(\n",
    "    df_train,\n",
    "    IMAGE_ROOT_TRAIN,\n",
    "    transform=transform_train\n",
    ")\n",
    "\n",
    "val_dataset = ArtDataset(\n",
    "    df_val,\n",
    "    IMAGE_ROOT_VAL,\n",
    "    transform=transform_val\n",
    ")\n",
    "\n",
    "test_dataset = ArtDataset(\n",
    "    df_test,\n",
    "    IMAGE_ROOT_TEST,\n",
    "    transform=transform_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7420786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,     # ajuster selon ton CPU\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,     # ajuster selon ton CPU\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,     # ajuster selon ton CPU\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac51ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3):\n",
    "        self.patience = patience\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.counter = 0\n",
    "        self.stop = False\n",
    "\n",
    "    def step(self, val_loss):\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8456ade3",
   "metadata": {},
   "source": [
    "### 1. EfficientNet B0/B1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45e9a8",
   "metadata": {},
   "source": [
    "→ Scaling composé (profondeur + largeur + résolution)\n",
    "→ Très efficace en vision\n",
    "\n",
    "Une architecture optimisée moderne améliore-t-elle la reconnaissance stylistique ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5cdbf1",
   "metadata": {},
   "source": [
    "#### 3.1 Charger le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81159fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b0 = get_model(\"efficientnet_b0\", num_classes=23)\n",
    "model_b0 = model_b0.to(device)\n",
    "model_b1 = get_model(\"efficientnet_b1\", num_classes=23)\n",
    "model_b1 = model_b1.to(device)\n",
    "\n",
    "num_classes = df_train[\"style_encoded\"].nunique()\n",
    "\n",
    "# ajout de label smoothing pour la cross entropy loss\n",
    "# label smoothing permet de rendre le modèle moins confiant dans ses prédictions,\n",
    "# ce qui peut aider à améliorer la généralisation et réduire le surapprentissage\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "optimizer_b0 = torch.optim.Adam(\n",
    "    model_b0.fc.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "optimizer_b1 = torch.optim.Adam(\n",
    "    model_b1.fc.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "## compter le nb de param\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Trainable parameters:\", count_parameters(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4403f1",
   "metadata": {},
   "source": [
    "#### 3.2 Entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24098a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "\n",
    "NUM_EPOCHS_FREEZE = 10\n",
    "history_freeze_b0 = train_model(\n",
    "    model_b0,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer_b0,\n",
    "    device,\n",
    "    num_epochs=NUM_EPOCHS_FREEZE,\n",
    "    early_stopping=early_stopping\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b5962e",
   "metadata": {},
   "source": [
    "#### 3.3 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9932dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history_freeze_b0[\"train_acc\"]\n",
    "val_acc   = history_freeze_b0[\"val_acc\"]\n",
    "\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "plt.title(\"EfficientNet B0 Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix :\n",
    "\n",
    "class_names = sorted(df_train[\"style\"].unique())\n",
    "\n",
    "cm = compute_confusion_matrix(\n",
    "    model_b0,\n",
    "    val_loader,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(cm, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c3504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(df_train[\"style\"].unique())\n",
    "\n",
    "acc_per_style = accuracy_per_class(\n",
    "    model_b0,\n",
    "    val_loader,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "results = list(zip(class_names, acc_per_style))\n",
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for style, acc in results:\n",
    "    print(f\"{style}: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fed949",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_accuracy_per_style(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed95424",
   "metadata": {},
   "source": [
    "#### 1.6.2 Evaluation sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0466e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_weights = model_b0.state_dict()\n",
    "\n",
    "test_acc, test_cm, report = evaluate_model(model_b0, test_loader, device)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb15221",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Confusion Matrix:\")\n",
    "plot_confusion_matrix(test_cm, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d14aea",
   "metadata": {},
   "source": [
    "### Modele b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d73e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_freeze_b1 = train_model(\n",
    "    model_b1,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer_b1,\n",
    "    device,\n",
    "    num_epochs=NUM_EPOCHS_FREEZE,\n",
    "    early_stopping=early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history_freeze_b1[\"train_acc\"]\n",
    "val_acc   = history_freeze_b1[\"val_acc\"]\n",
    "\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "plt.title(\"ResNet18 Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2714fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix :\n",
    "\n",
    "class_names = sorted(df_train[\"style\"].unique())\n",
    "\n",
    "cm = compute_confusion_matrix(\n",
    "    model_b1,\n",
    "    val_loader,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(cm, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0911c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = sorted(df_train[\"style\"].unique())\n",
    "\n",
    "acc_per_style = accuracy_per_class(\n",
    "    model_b1,\n",
    "    val_loader,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "results = list(zip(class_names, acc_per_style))\n",
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for style, acc in results:\n",
    "    print(f\"{style}: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e38596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_accuracy_per_style(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6275a1ff",
   "metadata": {},
   "source": [
    "#### Evaluation sur l'ensemble de test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_weights = model_mn.state_dict()\n",
    "\n",
    "test_acc, test_cm, report = evaluate_model(model_mn, test_loader, device)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b464492",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Confusion Matrix:\")\n",
    "plot_confusion_matrix(test_cm, class_names)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
