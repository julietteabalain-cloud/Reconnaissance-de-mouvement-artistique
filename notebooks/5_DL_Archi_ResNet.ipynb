{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6c5dea6",
   "metadata": {},
   "source": [
    "# <center> Tests de différentes architectures ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6532d941",
   "metadata": {},
   "source": [
    "On compare ici différentes architectures avec exactement les mêmes hyperparamètres que pour ResNet18 c'est à dire : \n",
    "- Même split train / val / test\n",
    "- Même preprocessing\n",
    "- Même nombre d’epochs\n",
    "- Même optimizer (Adam)\n",
    "- Même early stopping\n",
    "\n",
    "Stratégie en 2 phases :\n",
    "\n",
    "Phase 1 — Head-only training (comme ResNet18, on freeze tous les paramètres du modèle et on entraine uniquement la couche finale)\n",
    "→ Permet comparaison équitable\n",
    "\n",
    "Phase 2 — Fine-tuning partiel (optionnel mais intéressant, on débloque les 1-2 dernières couches mais risque de surapprentissage)\n",
    "→ Permet voir si les performances stagnent à cause du gel\n",
    "\n",
    "Pour chaque modèle : \n",
    "| Modèle | Accuracy | F1 weighted | Params | Temps d’entraînement |\n",
    "| ------ | -------- | ----------- | ------ | -------------------- |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755820ed",
   "metadata": {},
   "source": [
    "### 0. Préparation des hyper-paramètres et du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc6e2c0",
   "metadata": {},
   "source": [
    "#### Imports de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504c0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2580b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Pour que notre archi fonctionne avec google colab\n",
    "\n",
    "!git clone https://github.com/julietteabalain-cloud/Reconnaissance-de-mouvement-artistique.git\n",
    "!cd /content/Reconnaissance-de-mouvement-artistique && git pull\n",
    "%cd /content/Reconnaissance-de-mouvement-artistique\n",
    "import sys\n",
    "sys.path.append(\".\")  # pour que src/ soit importable\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f3d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset_dl import ArtDataset\n",
    "from src.train import train_model, train_one_epoch, validate_one_epoch\n",
    "\n",
    "from src.dataset import load_df_train_test_val, load_df\n",
    "from src.preprocessing import clean_dataset\n",
    "\n",
    "from src.models import get_model\n",
    "from src.evaluate import *\n",
    "from src.utils import set_seed\n",
    "\n",
    "#Fixer l'initialisation aléatoire pour la reproductibilité\n",
    "set_seed(42)\n",
    "\n",
    "#pour avoir acces au GPU si dispo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"/content/deepl-projet\")\n",
    "DATA_ROOT = Path(\"/content/drive/MyDrive/DeepLearning/WikiArt_Subset\")\n",
    "\n",
    "\n",
    "df_test, df_train, df_val = load_df_train_test_val(DATA_ROOT)\n",
    "df = load_df(DATA_ROOT)\n",
    "\n",
    "df, df_train, df_val, df_test = clean_dataset(df, df_train, df_val, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3d8b1",
   "metadata": {},
   "source": [
    "#### Dataset de deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2522a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "    # ajout de data augmentation pour le training set\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_ROOT_TRAIN = DATA_ROOT / \"train\"\n",
    "IMAGE_ROOT_VAL = DATA_ROOT / \"val\"\n",
    "IMAGE_ROOT_TEST = DATA_ROOT / \"test\"\n",
    "\n",
    "train_dataset = ArtDataset(\n",
    "    df_train,\n",
    "    IMAGE_ROOT_TRAIN,\n",
    "    transform=transform_train\n",
    ")\n",
    "\n",
    "val_dataset = ArtDataset(\n",
    "    df_val,\n",
    "    IMAGE_ROOT_VAL,\n",
    "    transform=transform_val\n",
    ")\n",
    "\n",
    "test_dataset = ArtDataset(\n",
    "    df_test,\n",
    "    IMAGE_ROOT_TEST,\n",
    "    transform=transform_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,     # ajuster selon ton CPU\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,     # ajuster selon ton CPU\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=2,     # ajuster selon ton CPU\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e885a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3):\n",
    "        self.patience = patience\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.counter = 0\n",
    "        self.stop = False\n",
    "\n",
    "    def step(self, val_loss):\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2f038f",
   "metadata": {},
   "source": [
    "### 1. ResNet34"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bee020",
   "metadata": {},
   "source": [
    "→ Même famille que ResNet18\n",
    "→ Plus profond (34 couches)\n",
    "→ Même logique de skip connections\n",
    "\n",
    "Est-ce que l’augmentation de profondeur améliore réellement la reconnaissance stylistique ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818ce10d",
   "metadata": {},
   "source": [
    "#### 1.1 Charger le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1f7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rn = get_model(\"resnet34\", num_classes=23)\n",
    "model_rn = model_rn.to(device)\n",
    "\n",
    "num_classes = df_train[\"style_encoded\"].nunique()\n",
    "\n",
    "# ajout de label smoothing pour la cross entropy loss\n",
    "# label smoothing permet de rendre le modèle moins confiant dans ses prédictions,\n",
    "# ce qui peut aider à améliorer la généralisation et réduire le surapprentissage\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model_rn.fc.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8533ea",
   "metadata": {},
   "source": [
    "#### 1.2 Entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfbd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utils import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "\n",
    "NUM_EPOCHS_FREEZE = 10\n",
    "history_freeze_rn = train_model(\n",
    "    model_rn,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=NUM_EPOCHS_FREEZE,\n",
    "    early_stopping=early_stopping\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7020a89",
   "metadata": {},
   "source": [
    "#### 1.3 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "train_acc = history_freeze_rn[\"train_acc\"]\n",
    "val_acc   = history_freeze_rn[\"val_acc\"]\n",
    "\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "plt.title(\"ResNet34 Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de3478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix :\n",
    "\n",
    "class_names = sorted(df_train[\"style\"].unique())\n",
    "\n",
    "cm = compute_confusion_matrix(\n",
    "    model_rn,\n",
    "    val_loader,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(cm, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09dbd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(df_train[\"style\"].unique())\n",
    "\n",
    "acc_per_style = accuracy_per_class(\n",
    "    model_rn,\n",
    "    val_loader,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "results = list(zip(class_names, acc_per_style))\n",
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for style, acc in results:\n",
    "    print(f\"{style}: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f24e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_accuracy_per_style(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cebd95",
   "metadata": {},
   "source": [
    "#### 1.6.2 Evaluation sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_weights = model_rn.state_dict()\n",
    "\n",
    "test_acc, test_cm, report = evaluate_model(model_rn, test_loader, device)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b8418",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Confusion Matrix:\")\n",
    "plot_confusion_matrix(test_cm, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
